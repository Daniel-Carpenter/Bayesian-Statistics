---
title:    "Assignment 4"
subtitle: "Bayesian Statistics"
author:   "Daniel Carpenter"
date:     "April 2022"
fontsize: 12pt
geometry: margin=1in
output:
  html_document: 
    toc: yes
    toc_float: yes
    theme: yeti
  # github_document:
  #   toc: yes
  #   # number_sections: yes
  #   toc_depth: 2
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(
	echo = TRUE,
	include = TRUE,
	message = FALSE,
	warning = FALSE
)
```


All questions and parts done completely.    

---

# Task 1 - GLM

## Overview of Problem 

### Soft Drink Delivery Times Problem
* Goal: estimation of the required time needed by each employee to refill an automatic vending machines owned and served by the company. 
* For this reason, a small quality assurance study was set-up by an industrial engineer of the company. 
  * As the response variable he considered the `total service time` (measured in minutes) of each machine, including its stocking with beverage products and any required maintenance or housekeeping. 
  * After examining the problem, the industrial engineer recommended two important variables which affect delivery time:  

1. the `number of cases of stocked products` and   
2. the `distance walked by the employee` (measured in feet).  

A dataset of *25 observations* was collected.  

<br>

## `a` Mathematics  

* The *linear predictor* of this data are the `cases` and `distance` variables  
* Since the *predicted variable* `time` is interval data, therefore:
  * The *link* function will be linear $\mu = lin(x)$
  * the *Metric* scale will be used. 
  * Since the Metric scale is used, a typical *noise distribution* for Metric scale types of predicted variables is normally distributed, or $y$ ~ $N(\mu, \sigma)$

### JAGS Model

```{r setupSoftDrinkJAGS}
# The JAGS Model
modelString = 
  "
  model {
  
    # model’s likelihood 
    for (i in 1:n) { 
      time[i] ~ dnorm( mu[i], tau ) # stochastic componenent 
      mu[i] <- beta0 + (beta1 * cases[i]) + (beta2 * distance[i]) 
    }
  
    # prior distributions 
    beta0 ~ dnorm(  0.0, 1.0E-4)  
    beta1 ~ dnorm(  0.0, 1.0E-4)  
    beta2 ~ dnorm(  0.0, 1.0E-4) 
    tau   ~ dgamma( 0.01, 0.01 ) 
  }
  "
```

<br>

## `b` Distribution of Data

### Data for Model
```{r setupSoftDrinkData}
# Data from soft drink experiment. See details below
dataList  = 
  list(n = 25,
       
       # Total Service time (predicted variable)
       # Measure: minutes
       time = c(16.68, 11.5, 12.03, 14.88, 
                13.75, 18.11, 8, 17.83, 79.24, 
                21.5, 40.33, 21, 13.5, 19.75, 
                24, 29, 15.35, 19, 9.5, 35.1,
                17.9, 52.32, 18.75, 19.83, 10.75), 
       
       # Distance an employee walks on foot to the vending machine 
       # (predictor variable 1)
       # Measure: feet
       distance = c(560, 220, 340, 80, 150, 330, 
                    110, 210, 1460, 605, 688, 215,
                    255, 462, 448, 776, 200, 132, 
                    36, 770, 140, 810, 450, 635, 150),
       
       # Number of cases of stocked products to restock
       # (predictor variable 2)
       # Measure: Number of cases of product
       cases = c( 7, 3, 3, 4, 6, 
                  7, 2, 7, 30, 5, 
                  16, 10, 4, 6, 9,
                  10, 6, 7, 3, 17, 
                  10, 26, 9, 8, 4) 
       )
```


### Examine the Data
```{r setupSoftDrinkDataPlots, cache=TRUE}
library(tidyverse)
library(ggplot2)

# Boxplots of the data
df.softDrinks <- data.frame(dataList$time, dataList$distance, dataList$cases)
colnames(df.softDrinks) <- c('time', 'distance', 'cases')
df.softDrinks <- df.softDrinks%>%
  pivot_longer(cols      = everything(),
               names_to  = 'name',
               values_to = 'value')

# Show some of the pivoted Dataset
head(df.softDrinks)

# Create the distribution of data plot
df.softDrinks %>%
  ggplot(aes(x     = name,
             y     = value)) +
  theme_minimal() +
  
  # Create a violin plot under the boxplot to view tails
  geom_violin(color = 'skyblue3',
               fill  = 'skyblue',
               alpha = 0.5) + 
  
  # Create the box plot
  geom_boxplot(color = 'skyblue4',
               fill  = 'grey99',
               alpha = 0.25) +
  
  # Wrap each variable on the columns
  facet_wrap(~name,
             ncol=3,
             scales = 'free') + 
  labs(title = 'Distribution of Data in Dataset',
       subtitle = 'Daniel Carpenter',
       x = '',
       y = 'Value of Data',
       caption = 'Please note varying scales on y-axis for each small multiple (facet)')

# Scatter of the data
# Function to see data: how does prediced value compare to the predictor?
getGLMPlot <- function(predictedValue, predictor, methodName = 'glm', ...)
{
  df <- data.frame(predictedValue, predictor)
  colnames(df) <- c('predictedValue', 'predictor')
  
  plot.glm <- df %>% 
    ggplot(aes(y = predictedValue,
               x = predictor)) +
    labs(title    = 'Snapshot of Data',
         subtitle = 'Daniel Carpenter',
         caption = 'This view is only to see how the two variables move together. Does not assume causal or independant relationship.',
         ...) +
    theme_minimal() +
    
    # Points
    geom_point(color = 'steelblue3') +
    
    # Using a GLM smoother
    geom_smooth(method = methodName,
                color = 'grey80',
                linetype = 'dotdash',
                fill = 'grey87')
  
  # print(plot.glm)
  return(plot.glm)
}

# Distance as a predictor
getGLMPlot(predictedValue = dataList$time    , y = 'Time',
           predictor      = dataList$distance, x = 'Distance')

# Num. Cases as a predictor
getGLMPlot(predictedValue = dataList$time, y = 'Time',
           predictor      = dataList$cases, x = 'Number of Cases')
```


### MCMC Model Control Inputs
```{r, setupSoftDrinkInputs}
# Model Name and Root
fileNameRoot= "Task 1 JAGS Output (Soft Drinks)/" # Directory
modelName   = 'SoftDrinks'      # Name of the model for File Naming


## MCMC Controls
adaptSteps  = 500               # Number of steps to adapt the samplers
burnInSteps = 1000              # Number of steps to burn-in the chains
nChains     = 3                 # nChains should be 2 or more for diagnostics 
nIter       = 10000             # Total Number of iterations to perform


## Parameter Definitions
parameters  = c("tau",          # The parameters to be monitored
                "beta0", 
                "beta1", 
                'beta2') 
```


<br>

## `c-g`  

### Function to Run the JAGS Model
```{r runSoftDrinkJAGS, echo=TRUE}
runJagsFunction <- function(modelString, parameters, nIter=10000, # Total iterations
                            initsList   = list( tau   = 1,  # Initial parameter values
                                                beta0 = 1, 
                                                beta1 = 0, 
                                                beta2 = 0 )) {
  
  source("DBDA2E-utilities.R") # Must be in R's current working directory.
  library(rjags)
  
  # Create the directory for the JAGS output
  dir.create(fileNameRoot)
  
  # Create a text file to hold the model string
  writeLines( modelString , con=paste0(modelName, ".txt") )
  
  # Run the Chains:
  jagsModel = jags.model(file     = paste0(modelName, ".txt"), 
                         data     = dataList, 
                         inits    = initsList, 
                         n.chains = nChains,
                         n.adapt  = adaptSteps 
                         )
  
  # Burn-in:
  cat( "Burning in the MCMC chain...\n" )
  update( jagsModel , n.iter=burnInSteps )
  
  # Sample MCMC
  cat( "Sampling final MCMC chain...\n" )
  codaSamples = coda.samples( jagsModel, variable.names=parameters, n.iter=nIter )
  
  # Note the resulting codaSamples object has these indices: 
  #   codaSamples[[ chainIdx ]][ stepIdx , paramIdx ]
  
  # Save the coda samples
  save( codaSamples , file=paste0(fileNameRoot,"Mcmc.Rdata") )
  
  return(codaSamples)
}
```

### Run Jags Model
```{r runJags1, out.width = "720px", cache=TRUE}
# Run the fun and store
codaSamples <- runJagsFunction(modelString, parameters)

# Diagnostics and Posteriors ----------------------------------------

# Tau
varName = paste0(parameters[1])
diagMCMC( codaObject=codaSamples , parName=varName );
saveGraph( file=paste0(fileNameRoot,varName) , type="png" )

openGraph(); par( mar=c(3.5,0.5,2.5,0.5) , mgp=c(2.25,0.7,0) )
plotPost( codaSamples[,varName] , main=paste0('Posterior Distribution of ', varName) , xlab=paste0(varName), ROPE = c(0.046992, 0.15745)) # from summary(codaSamples)

# Beta 0
varName = paste0(parameters[2])
diagMCMC( codaObject=codaSamples , parName=varName );
saveGraph( file=paste0(fileNameRoot,varName) , type="png" )

openGraph(); par( mar=c(3.5,0.5,2.5,0.5) , mgp=c(2.25,0.7,0) )
plotPost( codaSamples[,varName] , main=paste0('Posterior Distribution of ', varName) , xlab=paste0(varName), ROPE = c(0.086928 , 4.64718)) # from summary(codaSamples)

# Beta 1
varName = paste0(parameters[3])
diagMCMC( codaObject=codaSamples , parName=varName );
saveGraph( file=paste0(fileNameRoot,varName) , type="png" )

openGraph(); par( mar=c(3.5,0.5,2.5,0.5) , mgp=c(2.25,0.7,0) )
plotPost( codaSamples[,varName] , main=paste0('Posterior Distribution of ', varName) , xlab=paste0(varName), ROPE = c(1.263161 , 1.97443)) # from summary(codaSamples)

# Beta 2
varName = paste0(parameters[4])
diagMCMC( codaObject=codaSamples , parName=varName );
saveGraph( file=paste0(fileNameRoot,varName) , type="png" )

openGraph(); par( mar=c(3.5,0.5,2.5,0.5) , mgp=c(2.25,0.7,0) )
plotPost( codaSamples[,varName] , main=paste0('Posterior Distribution of ', varName) , xlab=paste0(varName), ROPE = c(0.006817 , 0.02172)) # from summary(codaSamples)

# graphics.off()

# Density Plots
library(ggmcmc)
s = ggs(codaSamples)
d = ggs_density(s)
print(d)

# Using classical methods (point estimates)
est.softDrink <- glm(time ~ distance + cases, data = dataList)
summary(est.softDrink)

# Using Baysian Methods
summary(codaSamples)
```


## `h` Formula for Model
$$
miles = \beta_0 + \beta_1 \times distance + \beta_2 \times cases + \epsilon
$$

## `i` Interpreation of Results

### For each additional `case` stocked by the employee...   

a - How much delivery time will be required on average (point estimate)? 

* 0.01448 minutes for an additional case stocked  
    
b - How much delivery time will be required on average (interval estimate) and with what posterior   probability?

* There is a probability of 95% that the delivery time between 0.007017 and 0.02198 minutes for an additional 100 ft. walked by the employee.  

<br>

### For every increase of walking `distance` by 100 feet...   
a - What delivery time will be required on average (point estimate)?   

* 1.61015 minutes for an additional 100 ft walked by the employee (I am assuming that the units for the data is per 100 ft. If it was per 1 ft. then it would be 1.61015 * 100)     
    
b - What delivery time will be required on average ( interval  
estimate) and with what posterior probability?

* There is a probability of 95% that the delivery time between 1.250213 and 1.96077 minutes  for an additional 100 ft. walked by the employee. (Note assumption in bullet `a`)  

*Estimates above are approximate by nature of MCMC*


---

<br>

## `j` Add `typical.y`

* The engineer wished to find a typical or representative delivery route.   
* He suggested the following code chunk.  

### New Jags Model
```{r setupNewSoftDrinkJAGS}
# The JAGS Model
modelString2 = 
  "
  model {
  
    # model’s likelihood 
    for (i in 1:n) { 
      time[i] ~ dnorm( mu[i], tau ) # stochastic componenent 
      
      # link and linear predictor 
      # In JAGS, ilogit is logistic. Use logistic since not 0/1 predicted values
      mu[i]     <- beta0 + (beta1 * cases[i]) + (beta2 * distance[i]) 
    }
    
    typical.y <- beta0 + beta1 * mean(cases[]) + beta2 * mean(distance[])
    
    # prior distributions 
    beta0 ~ dnorm(  0.0, 1.0E-4)   
    beta1 ~ dnorm(  0.0, 1.0E-4)   
    beta2 ~ dnorm(  0.0, 1.0E-4) 
    tau   ~ dgamma( 0.01, 0.01 ) 
  }
  "
```

### Run Jags Model
> Note only *monitoring* `typical.y`  

```{r runJags2, cache=TRUE, out.width="720px"}
# Run the fun and store
codaSamples <- runJagsFunction(modelString2, 
                               parameters  = c('typical.y')) # Monitor only R2B typical.y

# Diagnostics and Posteriors ----------------------------------------

# Note not monitoring other parameters to keep the file cleaner.

# Get Plots for typical.y
varName = 'typical.y'
diagMCMC( codaObject=codaSamples , parName=varName );
saveGraph( file=paste0(fileNameRoot,varName) , type="png" )

openGraph(); par( mar=c(3.5,0.5,2.5,0.5) , mgp=c(2.25,0.7,0) )
plotPost( codaSamples[,varName] , main=paste0('Posterior Distribution of ', varName) , xlab=paste0(varName), ROPE = c(21.045328  , 23.7713)) # from summary(codaSamples)

# graphics.off()

# Using Baysian Methods
summary(codaSamples)
```

### Interpretation of `typical.y`:
* The mean  typical outcome of `time` is around 22.3816. I find this interesting given the boxplots showing a median value slightly less than 20 () created at the top of the file).
* There is a probability of 95% that the typical outcome of `time` of will fall between 21 and 23.7
* The param. value’s trace has a defined range and hovers around mean value.  
* No issues with autocorrelation, as it drops significantly immediately.  
* Shrink factor stabilizes (good)  
* Chain densities represent each other well. Slight variation near median values.

*Estimates above are approximate by nature of MCMC*  


---

<br>

## `l` Add $R^{2}_{B}$
* $R^{2}_{B}$ is the sample variance of `Y`  
* $\sigma^2$ is the variance of the random variable `Y` in the model   
* $R^{2}_{B}$ is the reduction in uncertainty of the response variable Y through the model using explanatory variables x  

```{r setup3SoftDrinkJAGS}
# The JAGS Model
modelString3 = 
  "
  model {
  
    # model’s likelihood 
    for (i in 1:n) { 
      time[i] ~ dnorm( mu[i], tau ) # stochastic componenent 
      
      # link and linear predictor 
      # In JAGS, ilogit is logistic. Use logistic since not 0/1 predicted values
      mu[i]     <- beta0 + (beta1 * cases[i]) + (beta2 * distance[i]) 
    }
    
    typical.y <- beta0 + beta1 * mean(cases[]) + beta2 * mean(distance[])
    
    # prior distributions 
    beta0 ~ dnorm(  0.0, 1.0E-4)   
    beta1 ~ dnorm(  0.0, 1.0E-4)   
    beta2 ~ dnorm(  0.0, 1.0E-4) 
    tau   ~ dgamma( 0.01, 0.01 ) 
    
		# definition of sigma
		s2<-1/tau
		s <-sqrt(s2)
		
		# calculation of the sample variance
	  for (i in 1:n){ c.time[i]<-time[i]-mean(time[]) } 
		sy2 <- inprod( c.time[], c.time[] )/(n-1)
		
		# calculation of Bayesian version R squared
		R2B <- 1 - s2/sy2
    
		# Posterior Probabilities
		p.beta0 <- step( beta0 )
		p.beta1 <- step( beta1 )
		p.beta2 <- step( beta2 )
  }
  "
```

### Run Jags Model
> Note only *monitoring* $R^{2}_{B}$  


```{r runJags3, cache=TRUE, out.width="720px"}
# Run the fun and store
codaSamples <- runJagsFunction(modelString3, 
                               parameters  = c('beta2', # want to monitor this to get point est
                                               'R2B') # Monitor only R2B
                               )

# Diagnostics and Posteriors ----------------------------------------

# Note not monitoring other parameters to keep the file cleaner.

# Beta 2
varName = paste0(parameters[4])
diagMCMC( codaObject=codaSamples , parName=varName );
saveGraph( file=paste0(fileNameRoot,varName) , type="png" )

openGraph(); par( mar=c(3.5,0.5,2.5,0.5) , mgp=c(2.25,0.7,0) )
plotPost( codaSamples[,varName] , main=paste0('Posterior Distribution of ', varName) , xlab=paste0(varName), ROPE = c(0.006817 , 0.02172)) # from summary(codaSamples)


# Plots for R2B
varName = 'R2B'
diagMCMC( codaObject=codaSamples , parName=varName );
saveGraph( file=paste0(fileNameRoot,varName) , type="png" )

openGraph(); par( mar=c(3.5,0.5,2.5,0.5) , mgp=c(2.25,0.7,0) )
plotPost( codaSamples[,varName] , main=paste0('Posterior Distribution of ', varName) , xlab=paste0(varName), ROPE = c(0.911270   , 0.97351)) # from summary(codaSamples)

# graphics.off()

# Using Baysian Methods
su = summary(codaSamples)
su
```

### Interpretation of $R2B$:
* The mean  typical outcome of `time` is around 0.9515  
* There is a probability of 95% that the typical outcome of `time` of will fall between 0.911409  and 0.97363
* The param. value’s trace has a defined range and hovers around mean value but dips low sometimes.  
* No issues with autocorrelation, as it drops significantly immediately.  
* Shrink factor stabilizes (good)  
* Chain densities represent each other well.

*Estimates above are approximate by nature of MCMC*  


### Calculate $P(\beta_2 > 0.01|D)$
```{r}
# Since Beta2 must be distributed normally, here get the mean and sd
mu    = su$statistics[2,1]
sigma = su$statistics[2,2]

# Probability that beta2 > 0.01, given the data
probExact = 1 - pnorm(0.01, mu, sigma)

paste('Probability that beta2 > 0.01, given the data:', round(probExact, 3))

```

---

<br>

# Task 2

![Task 2 Description](Images/Task2.png)

## `a` Data

### Data for Model
```{r setupBeetleData}
dataList <- list(
                 # Dose exposed to the beetle
                 x = c(1.6907, 1.7242, 1.7552, 1.7842, 
                       1.8113, 1.8369, 1.8610, 1.8839), 
                 
                 # Concentrations of carbon disulphide 
                 n = c(59, 60, 62, 56, 63, 59, 62, 60), 
                 
                 # Number of beetles killed
                 y = c(6, 13, 18, 28, 52, 53, 61, 60)
                 )
```

### Plots of data
```{r beetlePlots}
require(tidyverse)
# Distance as a predictor
getGLMPlot(predictedValue = dataList$y, y = 'Number of beetles killed',
           predictor      = dataList$x, x = 'Dose exposed to the beetle',
           methodName = 'loess')  + # just using this to see the trend
  geom_text(aes(label = paste0('n=', dataList$n)),
                nudge_y = max(dataList$y) * 0.125,
            size = 3,
            color = 'grey40')
  
```

## `b` JAGS Model (*Centered*)
> Model centered Independant variable *dose* (`x`) around it's mean

* To help convergence, *centering* causes nearly uncorrelated regression coeff's
* [See reasoning for centering article](https://agabrioblog.onrender.com/tutorial/multiple-linear-regression-jags/multiple-linear-regression-jags/)  

### The JAGS Model for Beetles
```{r beetleJAGS}
# The JAGS Model
modelString = 
"
model {

  for (i in 1:8) {
  
    # link and linear predictor 
    y[i] ~ dbin(p[i], n[i]) 
    
          
    # In JAGS, ilogit is logistic. Use logistic since not 0/1 predicted values
    logit(p[i]) <- beta0 + ( beta1 * (x[i] - mean(x[])) ) # Note centering around mean
    
    phat[i] <- y[i]/n[i] 
    yhat[i] <- n[i]*p[i] 
  } 
  
  # prior distributions 
  beta0 ~ dnorm(  0.0, 0.001)  
  beta1 ~ dnorm(  0.0, 0.001)  
}
"
```

### MCMC Model Control Inputs for Beetles
```{r, setupBeetleInputs}
# Model Name and Root
fileNameRoot= "Task 2 JAGS Output (Beetles)/" # Directory
modelName   = 'Beetles'      # Name of the model for File Naming


## MCMC Controls
adaptSteps  = 500               # Number of steps to adapt the samplers
burnInSteps = 1000              # Number of steps to burn-in the chains
nChains     = 3                 # nChains should be 2 or more for diagnostics 


## Parameter Definitions
parameters  = c("beta0", 
                "beta1") 
```

## `c` Run Jags Model (*Centered*)
```{r runBeetlesJags1, echo=TRUE, out.width = "720px", cache=TRUE}
# Run the fun and store
codaSamples <- runJagsFunction(modelString, parameters, nIter=5000, # Total iterations
                               initsList   = list( beta0 = 0,  # Note initial values
                                                   beta1 = 0 )
                               )


# Diagnostics and Posteriors ----------------------------------------

# Beta 0
varName = paste0(parameters[1])
diagMCMC( codaObject=codaSamples , parName=varName );
saveGraph( file=paste0(fileNameRoot,varName) , type="png" )

openGraph(); par( mar=c(3.5,0.5,2.5,0.5) , mgp=c(2.25,0.7,0) )
plotPost( codaSamples[,varName] , main=paste0('Posterior Distribution of ', varName) , xlab=paste0(varName), ROPE = c(0.4813 , 1.031)) # from summary(codaSamples)

# Beta 1
varName = paste0(parameters[2])
diagMCMC( codaObject=codaSamples , parName=varName );
saveGraph( file=paste0(fileNameRoot,varName) , type="png" )

openGraph(); par( mar=c(3.5,0.5,2.5,0.5) , mgp=c(2.25,0.7,0) )
plotPost( codaSamples[,varName] , main=paste0('Posterior Distribution of ', varName) , xlab=paste0(varName), ROPE = c(29.1521  , 40.382)) # from summary(codaSamples)

# graphics.off()

# Density Plots
library(ggmcmc)
s = ggs(codaSamples)
d = ggs_density(s)
print(d)

# Using Baysian Methods
summary(codaSamples)
```

---

<br>

## `d` *Non-Centered* Independant Var

### JAGS Model (Non-Centered)
> Model does *not* centered Independant variable `dose`   
> See reasoning for centering on mean above    

### The JAGS Model for Beetles (*not centered*)
```{r beetleJAGS2}
# The JAGS Model
modelString = 
"
model {

  for (i in 1:8) {
  
    # link and linear predictor 
    y[i] ~ dbin(p[i], n[i]) 
    
          
    # In JAGS, ilogit is logistic. Use logistic since not 0/1 predicted values
    # Note that x is non-centered now since it is not centering around mean
    logit(p[i]) <- beta0 + ( beta1 * x[i] )      # Removed (x[i] - mean(x[]))
    
    phat[i] <- y[i]/n[i] 
    yhat[i] <- n[i]*p[i] 
  } 
  
  # prior distributions 
  beta0 ~ dnorm(  0.0, 0.001)  
  beta1 ~ dnorm(  0.0, 0.001)  
}
"
```

## `c` Run Jags Model (*Non-Centered*) 
* Note inputs same as last model except for `modelString` changed directly above

```{r runBeetlesJags2, echo=TRUE, out.width = "720px", cache=TRUE}
# Run the fun and store
codaSamplesNonCenter <- runJagsFunction(modelString, parameters, nIter=5000, # Total iterations
                                        initsList   = list( beta0 = 1, 
                                                            beta1 = 1 )
                                        )


# Diagnostics and Posteriors ----------------------------------------

# Beta 0
varName = paste0(parameters[1])
diagMCMC( codaObject=codaSamplesNonCenter , parName=varName );
saveGraph( file=paste0(fileNameRoot,varName) , type="png" )

openGraph(); par( mar=c(3.5,0.5,2.5,0.5) , mgp=c(2.25,0.7,0) )
plotPost( codaSamplesNonCenter[,varName] , main=paste0('Posterior Distribution of ', varName) , xlab=paste0(varName), ROPE = c(0.4813 , 1.031)) # from summary(codaSamplesNonCenter)

# Beta 1
varName = paste0(parameters[2])
diagMCMC( codaObject=codaSamplesNonCenter , parName=varName );
saveGraph( file=paste0(fileNameRoot,varName) , type="png" )

openGraph(); par( mar=c(3.5,0.5,2.5,0.5) , mgp=c(2.25,0.7,0) )
plotPost( codaSamplesNonCenter[,varName] , main=paste0('Posterior Distribution of ', varName) , xlab=paste0(varName), ROPE = c(29.1521  , 40.382)) # from summary(codaSamplesNonCenter)

# graphics.off()

# Density Plots
library(ggmcmc)
s = ggs(codaSamplesNonCenter)
d = ggs_density(s)
print(d)

# Using Baysian Methods
summary(codaSamplesNonCenter)
```


## `e` Interpretation (*Non-Centered*)  
* Parameter values never hover around the mean  
* High Autocorrelation occurs and never reduces.  
* Shrink factor unstable and never settles  
* Clearly, the model does not converge among the three chains.  

<br>

## `f` Pairs Plots
> Centered vs. Non-Centered Independant Variables

### Create the Plots

```{r, pairs, cache=TRUE}
require(ggmcmc)
library(GGally)

# Centered Independant Variable
ggs_pairs(ggs(codaSamples), 
          
          # Change to Contours
          lower = list(continuous =  'density'), 
          
          # Color by Chain and add transparency
          mapping = aes(color = Chain, alpha = 0.2)
          ) + 
  labs(title = 'Pair Plot of Logistic Simulation',
       subtitle = 'Centered Independant Variable | Daniel Carpenter\n') + 
  theme_minimal() + theme(text = element_text(color = 'grey25'))


# Centered Independent Variable
ggs_pairs(ggs(codaSamplesNonCenter), 
          
          # Change to Contours
          lower = list(continuous =  'density'), 
          
          # Color by Chain and add transparency
          mapping = aes(color = Chain, alpha = 0.2)
          ) + 
  labs(title = 'Pair Plot of Logistic Simulation',
       subtitle = 'Non-Centered Independant Variable | Daniel Carpenter\n') + 
  theme_minimal() + theme(text = element_text(color = 'grey25'))

```

<br>

### Pairs - Centering/Non-Centering

#### *Centering* accomplishes...  
* Centering allows for convergence among the chains  
* Low levels of cross-correlation  
* Extremely stable results  

<br>

## `g` Random vs. Non-Random Vars

Type       | Variables
-----------|-------------
Random     | p[i], y[i], yhat[i]
Not Random | beta0, beta1, phat[i], 

<br>

## `h` Jags Model using `Probit` (*Centered*)

### The JAGS Model for `Probit` Beetles
```{r beetleJAGS3}
# The JAGS Model
modelString = 
"
model {

  for (i in 1:8) {
  
    # link and linear predictor 
    y[i] ~ dbin(p[i], n[i]) 
    
    # Now using a probit
    probit(p[i]) <- beta0 + ( beta1 * (x[i] - mean(x[])) ) # Note centering around mean
          
    # Note The old logit method
    # logit(p[i]) <- beta0 + ( beta1 * (x[i] - mean(x[])) ) # Note centering around mean
    
    phat[i] <- y[i]/n[i] 
    yhat[i] <- n[i]*p[i] 
  } 
  
  # prior distributions 
  beta0 ~ dnorm(  0.0, 0.001)  
  beta1 ~ dnorm(  0.0, 0.001)  
}
"
```

### Run Jags Model `Probit` (*Centered*)
```{r runBeetlesJags3, echo=TRUE, out.width = "720px", cache=TRUE}
# Run the fun and store
codaSamples <- runJagsFunction(modelString, parameters, nIter=5000, # Total iterations
                               initsList   = list( beta0 = 0,  # Note initial values
                                                   beta1 = 0 )
                               )


# Diagnostics and Posteriors ----------------------------------------

# Beta 0
varName = paste0(parameters[1])
diagMCMC( codaObject=codaSamples , parName=varName );
saveGraph( file=paste0(fileNameRoot,varName) , type="png" )

openGraph(); par( mar=c(3.5,0.5,2.5,0.5) , mgp=c(2.25,0.7,0) )
plotPost( codaSamples[,varName] , main=paste0('Posterior Distribution of ', varName) , xlab=paste0(varName), ROPE = c(0.295   , 0.5969)) # from summary(codaSamples)

# Beta 1
varName = paste0(parameters[2])
diagMCMC( codaObject=codaSamples , parName=varName );
saveGraph( file=paste0(fileNameRoot,varName) , type="png" )

openGraph(); par( mar=c(3.5,0.5,2.5,0.5) , mgp=c(2.25,0.7,0) )
plotPost( codaSamples[,varName] , main=paste0('Posterior Distribution of ', varName) , xlab=paste0(varName), ROPE = c(16.947   , 22.7206)) # from summary(codaSamples)

# graphics.off()

# Density Plots
library(ggmcmc)
s = ggs(codaSamples)
d = ggs_density(s)
print(d)

# Using Baysian Methods
summary(codaSamples)

# Pairs plot
pairs <- ggs_pairs(s, 
                   
                   # Change to Contours
                   lower = list(continuous =  'density'), 
                   
                   # Color by Chain and add transparency
                   mapping = aes(color = Chain, alpha = 0.2)) +
  
                   labs(title = 'Pair Plot of Logistic Simulation',
                        subtitle = 'Non-Centered Independant Variable | Daniel Carpenter\n') + 
                   theme_minimal() + theme(text = element_text(color = 'grey25'))

print(pairs)
```

### Interpretation of Results (`Probit`)
* Similar outcome as the `logit` model (in terms of convergence and stationarity)  
* However, significantly different results for the point estimate of $\beta_1$.  

