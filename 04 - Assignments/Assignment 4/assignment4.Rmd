---
title:    "Assignment 4"
subtitle: "Bayesian Statistics"
author:   "Daniel Carpenter"
date:     "April 2022"
fontsize: 12pt
geometry: margin=1in
output:
  html_document:
    toc: yes
    toc_float: yes
  # github_document:
  #   toc: yes
  #   # number_sections: yes
  #   toc_depth: 2
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(
	echo = TRUE,
	include = TRUE,
	message = FALSE,
	warning = FALSE
)
```


All questions and parts done completely.    

---

# Task 1

## Overview of Problem 

### Soft Drink Delivery Times Problem
* Goal: estimation of the required time needed by each employee to refill an automatic vending machines owned and served by the company. 
* For this reason, a small quality assurance study was set-up by an industrial engineer of the company. 
  * As the response variable he considered the `total service time` (measured in minutes) of each machine, including its stocking with beverage products and any required maintenance or housekeeping. 
  * After examining the problem, the industrial engineer recommended two important variables which affect delivery time:  

1. the `number of cases of stocked products` and   
2. the `distance walked by the employee` (measured in feet).  

A dataset of *25 observations* was collected.  

### JAGS Model

* Since the 
* The *linear predictor* of this data are the `cases` and `distance` variables  
* Since the *predicted variable* `time` is interval data, therefore:
  * The *link* function will be linear $\mu = lin(x)$
  * the *Metric* scale will be used. 
  * Since the Metric scale is used, a typical *noise distribution* for Metric scale types of predicted variables is normally distributed, or $y$ ~ $N(\mu, \sigma)$

```{r setupSoftDrinkJAGS}
# The JAGS Model
modelString = 
  "
  model {
  
    # modelâ€™s likelihood 
    for (i in 1:n) { 
      time[i] ~ dnorm( mu[i], tau ) # stochastic componenent 
      
      # link and linear predictor 
      # In JAGS, ilogit is logistic. Use logistic since not 0/1 predicted values
      mu[i] <- beta0 + (beta1 * cases[i]) + (beta2 * distance[i]) 
    }
  
    # prior distributions 
    beta0 ~ dnorm(  0.0, 1.0E-4)  # Check! 
    beta1 ~ dnorm(  0.0, 1.0E-4)  # Check! 
    beta2 ~ dnorm(  0.0, 1.0E-4) 
    tau   ~ dgamma( 0.01, 0.01 ) 
  }
  "
```

### Data for Model
```{r setupSoftDrinkData}
# Data from soft drink experiment. See details below
dataList  = 
  list(n = 25,
       
       # Total Service time (predicted variable)
       # Measure: minutes
       time = c(16.68, 11.5, 12.03, 14.88, 
                13.75, 18.11, 8, 17.83, 79.24, 
                21.5, 40.33, 21, 13.5, 19.75, 
                24, 29, 15.35, 19, 9.5, 35.1,
                17.9, 52.32, 18.75, 19.83, 10.75), 
       
       # Distance an employee walks on foot to the vending machine 
       # (predictor variable 1)
       # Measure: feet
       distance = c(560, 220, 340, 80, 150, 330, 
                    110, 210, 1460, 605, 688, 215,
                    255, 462, 448, 776, 200, 132, 
                    36, 770, 140, 810, 450, 635, 150),
       
       # Number of cases of stocked products to restock
       # (predictor variable 2)
       # Measure: Number of cases of product
       cases = c( 7, 3, 3, 4, 6, 
                  7, 2, 7, 30, 5, 
                  16, 10, 4, 6, 9,
                  10, 6, 7, 3, 17, 
                  10, 26, 9, 8, 4) 
       )
```


### Examine the Data
```{r setupSoftDrinkDataPlots, cache=TRUE}
require(tidyverse)
require(ggplot2)

# Boxplots of the data
df.softDrinks <- data.frame(dataList$time, dataList$distance, dataList$cases)
colnames(df.softDrinks) <- c('time', 'distance', 'cases')
df.softDrinks <- df.softDrinks%>%
  pivot_longer(cols      = everything(),
               names_to  = 'name',
               values_to = 'value')

# Show some of the pivoted Dataset
head(df.softDrinks)

# Create the distribution of data plot
df.softDrinks %>%
  ggplot(aes(x     = name,
             y     = value)) +
  theme_minimal() +
  
  # Create a violin plot under the boxplot to view tails
  geom_violin(color = 'skyblue3',
               fill  = 'skyblue',
               alpha = 0.5) + 
  
  # Create the box plot
  geom_boxplot(color = 'skyblue4',
               fill  = 'grey99',
               alpha = 0.25) +
  
  # Wrap each variable on the columns
  facet_wrap(~name,
             ncol=3,
             scales = 'free') + 
  labs(title = 'Distribution of Data in Dataset',
       subtitle = 'Daniel Carpenter',
       x = '',
       y = 'Value of Data',
       caption = 'Please note varying scales on y-axis for each small multiple (facet)')

# Scatter of the data
# Function to see data: how does prediced value compare to the predictor?
getGLMPlot <- function(predictedValue, predictor, ...)
{
  df <- data.frame(predictedValue, predictor)
  colnames(df) <- c('predictedValue', 'predictor')
  
  plot.glm <- df %>% 
    ggplot(aes(y = predictedValue,
               x = predictor)) +
    labs(title    = 'Snapshot of Soft Drink Data',
         subtitle = 'Daniel Carpenter',
         caption = 'This view is only to see how the two variables move together. Does not assume causal or independant relationship.',
         ...) +
    theme_minimal() +
    geom_point(color = 'steelblue3') + 
    geom_smooth(method = 'glm',
                color = 'grey80',
                linetype = 'dotdash',
                fill = 'grey87')
  
  print(plot.glm)
}

# Distance as a predictor
getGLMPlot(predictedValue = dataList$time    , y = 'Time',
           predictor      = dataList$distance, x = 'Distance')

# Num. Cases as a predictor
getGLMPlot(predictedValue = dataList$time, y = 'Time',
           predictor      = dataList$cases, x = 'Number of Cases')
```


### MCMC Model Control Inputs
```{r, setupSoftDrinkInputs}
# Model Name and Root
fileNameRoot= "Task 1 JAGS Output (Soft Drinks)/" # Directory
modelName   = 'SoftDrinks'      # Name of the model for File Naming


## MCMC Controls
adaptSteps  = 500               # Number of steps to adapt the samplers
burnInSteps = 1000              # Number of steps to burn-in the chains
nChains     = 3                 # nChains should be 2 or more for diagnostics 
nIter       = 10000             # Total Number of iterations to perform


## Parameter Definitions
parameters  = c("tau",          # The parameters to be monitored
                "beta0", 
                "beta1", 
                'beta2') 
initsList   = list( tau   = 1,  # Initial parameter values
                    beta0 = 1, 
                    beta1 = 0, 
                    beta2 = 0 )
```

### Run the JAGS Model
```{r runSoftDrinkJAGS, echo=TRUE, out.width = "720px, cache=TRUE"}
source("DBDA2E-utilities.R") # Must be in R's current working directory.
library(rjags)

# Create the directory for the JAGS output
dir.create(fileNameRoot)

# Create a text file to hold the model string
writeLines( modelString , con=paste0(modelName, ".txt") )

# Run the Chains:
jagsModel = jags.model(file     = paste0(modelName, ".txt"), 
                       data     = dataList, 
                       inits    = initsList, 
                       n.chains = nChains,
                       n.adapt  = adaptSteps 
                       )

# Burn-in:
cat( "Burning in the MCMC chain...\n" )
update( jagsModel , n.iter=burnInSteps )

# Sample MCMC
cat( "Sampling final MCMC chain...\n" )
codaSamples = coda.samples( jagsModel, variable.names=parameters, n.iter=nIter )

# Note the resulting codaSamples object has these indices: 
#   codaSamples[[ chainIdx ]][ stepIdx , paramIdx ]

# Save the coda samples
save( codaSamples , file=paste0(fileNameRoot,"Mcmc.Rdata") )

# Save/show the MCMC Diagnostics for each parameter
for (varName in parameters) {
  
  # Output the data for each parameter defined above
  diagMCMC( codaObject=codaSamples , parName=varName )
  saveGraph( file=paste0(fileNameRoot,varName) , type="png" )
}
graphics.off()

# Print Graphs
knitr::include_graphics(paste0(fileNameRoot,parameters[1], '.png')) # Force to knit
knitr::include_graphics(paste0(fileNameRoot,parameters[2], '.png')) # Force to knit
knitr::include_graphics(paste0(fileNameRoot,parameters[3], '.png')) # Force to knit
knitr::include_graphics(paste0(fileNameRoot,parameters[4], '.png')) # Force to knit

# Using classical methods (point estimates)
est.softDrink <- glm(time ~ distance + cases, data = dataList)
summary(est.softDrink)

# Using Baysian Methods
summary(codaSamples)
```












